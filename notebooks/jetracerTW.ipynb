{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b177659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "import matplotlib.pyplot as plt\n",
    "from jetcam.csi_camera import CSICamera\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import PIL\n",
    "import pathlib\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b173d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CSICamera(width=224, height=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class imagereader:\n",
    "    def __init__(self):\n",
    "        self.camera = camera\n",
    "        self._oldimage = None\n",
    "        self.camera.running = True\n",
    "    \n",
    "    def read(self):\n",
    "        while True:\n",
    "            i = self.camera.value\n",
    "            try:\n",
    "                diff = np.abs(i[0] - self._oldimage[0])\n",
    "                diff = np.where(diff < 250, diff, 0)\n",
    "                diff = diff.sum()\n",
    "                if diff > 0:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "        self._oldimage = i\n",
    "        return PIL.Image.fromarray(self._oldimage[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccaee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = imagereader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ir.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    Augments an image for processing.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL image\n",
    "        \n",
    "    returns: tensor with an augmented version of the image\n",
    "    \"\"\"\n",
    "    #img = transforms.functional.to_grayscale(img)\n",
    "    X = transforms.functional.to_tensor(img) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6420ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class drive:\n",
    "    \"\"\"\n",
    "    ContextManager to drive the car and always stop when the context terminates\n",
    "    \"\"\"\n",
    "    def __init__(self, car, speed=-0.5):\n",
    "        self.car = car\n",
    "        self.speed = speed\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.car.throttle = self.speed\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        self.car.throttle = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab92c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model that will indicate if the track is visible on the camera.\n",
    "    \n",
    "    This version will adjust to images of any number of channels (e.g. grayscale or RBG)\n",
    "    \n",
    "    Args:\n",
    "        threshold: float (1.2) the threshold used to check for the track, you may need to alter this under different \n",
    "        lighting conditions or when using RGB images.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=1.2):\n",
    "        super().__init__()\n",
    "        self.threshold=threshold\n",
    "        self.stopmodel = self.create_model(1)\n",
    "    \n",
    "    def create_model(self, channels):\n",
    "        model = nn.Conv1d(channels, 1, kernel_size=3, padding=0)\n",
    "        model.weight.requires_grad = False\n",
    "        model.weight[...] = 1\n",
    "        model.bias.data = torch.tensor([0.0])\n",
    "        model.to(device)\n",
    "        return model\n",
    "\n",
    "    def forward(self, X):\n",
    "        if X.shape[1] != self.stopmodel.in_channels:\n",
    "            self.stopmodel = self.create_model(X.shape[1])\n",
    "        r = self.stopmodel(X[:,:,-1,:])\n",
    "        return (torch.min(r) > self.threshold).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd408ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_stop = StopModel(threshold=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75292766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate auto_stop\n",
    "auto_stop(preprocess_image(ir.read()).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceMonster(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(224*224, 100)\n",
    "        self.w2 = nn.Linear(100, 1)\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.w2(self.relu(self.w1(X.view(len(X), -1)))).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e238ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Perceptron.all.state'\n",
    "model = RaceMonster()\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.to(device)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alleen sturen\n",
    "count = 0\n",
    "with torch.no_grad():                         # no training\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        count += 1\n",
    "        clear_output()\n",
    "        print(f'fps {count / (time.time() - start)}')   # print fps\n",
    "        image = ir.read()                    # lees plaatje\n",
    "        X = preprocess_image(image)          # preprocess\n",
    "        X = X.unsqueeze(0)                   # (1,1,224,224)\n",
    "        X = X.to(device)                     # naar gpu\n",
    "        direction = model(X).cpu().item()    # voorspelling\n",
    "        car.steering = direction             # stuur auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d878c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stukje rijden\n",
    "with drive(car, speed=-0.5):\n",
    "    with torch.no_grad():                         # no training\n",
    "        while True:\n",
    "            image = ir.read()\n",
    "            X = preprocess_image(image)\n",
    "            X = X.unsqueeze(0)\n",
    "            X = X.to(device)\n",
    "            direction = model(X).cpu().item()\n",
    "            car.steering = direction\n",
    "            if auto_stop(X):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fdbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
